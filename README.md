# Intelligent Mini-Batch Sampling for Gradient Descent
Mini-batch gradient descent is a widely used algorithm to train classifiers. The standard way of selecting these batches is uniform sampling. This work presents various methods to improve diversity of the mini batch within each iteration while improving informativeness across iterations.

# Repo Heirarchy

- **Report** - Summarizes all the experiments and performance metrics of various sampling techniques.
- **Code** - Yet to be added
